# ======================================================================================
# [í”„ë¡œì íŠ¸] ì´ê¸°ì¢… ìŒì•… ë°ì´í„°ì…‹ì„ í™œìš©í•œ ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•
# [ìŠ¤í¬ë¦½íŠ¸ ëª©ì ] ALS ëª¨ë¸ì— ëŒ€í•œ ë‹¤ì°¨ì› ì‹¬ì¸µ ì„±ëŠ¥ í‰ê°€ ë° ì‚¬ë¡€ ì—°êµ¬
# [End-to-End ë‹¨ê³„] 6. í‰ê°€(Advanced Evaluation & Case Study)
#
# (ì´ì „ ì„¤ëª…ê³¼ ë™ì¼)
# ...
# [ì¶”ê°€ëœ ë‚´ìš©]
#  - ì •ëŸ‰ì  í‰ê°€ ì§€í‘œ(Precision, Similarity) ê³„ì‚° í›„, ë¬´ìž‘ìœ„ë¡œ ì„ ì •ëœ 5ëª…ì˜ ì‹¤ì œ
#    ì¶”ì²œ ì‚¬ë¡€ë¥¼ ì§ˆì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ í–‰ë™ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.
# ======================================================================================

import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
from implicit.als import AlternatingLeastSquares
import os
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import random # ðŸ’¥ðŸ’¥ðŸ’¥ ëžœë¤ ìƒ˜í”Œë§ì„ ìœ„í•´ ìž„í¬íŠ¸ ðŸ’¥ðŸ’¥ðŸ’¥

# --- 1. ì„¤ì • ---
DATA_PATH = '../../data/final-lastfm-data.csv'
K_FOR_RANKING = 10
Eth = 10 
factors = 50
regularization = 0.01
iterations = 20
random_state = 42

# --- 2. ë°ì´í„° ì¤€ë¹„ ---
df_raw = pd.read_csv(DATA_PATH)
user_counts = df_raw['user_id'].value_counts()
active_users = user_counts[user_counts >= Eth].index
df = df_raw[df_raw['user_id'].isin(active_users)].copy()
unique_users = df['user_id'].unique()
unique_items = df['title'].unique()
user_to_idx = {user: i for i, user in enumerate(unique_users)}
item_to_idx = {item: i for i, item in enumerate(unique_items)}
idx_to_user = {i: user for user, i in user_to_idx.items()}
idx_to_item = {i: item for item, i in item_to_idx.items()}
num_users = len(unique_users)
num_items = len(unique_items)

# --- 3. Train / Test ë°ì´í„° ë¶„í•  ---
train_df, test_df = train_test_split(
    df, test_size=0.2, stratify=df['user_id'], random_state=41
)
train_user_indices = train_df['user_id'].map(user_to_idx)
train_item_indices = train_df['title'].map(item_to_idx)
train_matrix = csr_matrix((train_df['play_count'].astype(float),
                           (train_user_indices, train_item_indices)),
                          shape=(num_users, num_items))
train_item_user = train_matrix.T.tocsr()

# --- 4. ALS ëª¨ë¸ í•™ìŠµ ---
model = AlternatingLeastSquares(factors=factors, regularization=regularization,
                                iterations=iterations, random_state=random_state)
model.fit(train_item_user, show_progress=True)


# --- 5. ë‹¤ì°¨ì› ì„±ëŠ¥ í‰ê°€ ë¡œì§ ---
# (ìƒëžµ - ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ì‹¤í–‰í•˜ì—¬ avg_precision, avg_recall, avg_genre_similarity ê³„ì‚°)
song_features_df = df.drop_duplicates(subset='title').set_index('title')
main_genres = ['Classic Rock', 'Hard Rock', 'Alternative & Indie Rock', 'Pop & Folk Rock', 'Pop', 'Jazz & Blues', 'R&B & Funk', 'Hip Hop', 'Electronic & Dance', 'Folk & Country', 'Reggae', 'Other']
existing_genre_cols = [col for col in main_genres if col in song_features_df.columns]
song_features_matrix_map = {title: features for title, features in zip(song_features_df.index, song_features_df[existing_genre_cols].values)}
precisions, recalls, all_users_avg_similarities = [], [], []
true_relevants = test_df.groupby('user_id')['title'].apply(set).to_dict()
test_users_indices = [user_to_idx[user] for user in true_relevants.keys() if user in user_to_idx]
# ðŸ’¥ðŸ’¥ðŸ’¥ ì‚¬ë¡€ ì—°êµ¬ë¥¼ ìœ„í•´ ì‚¬ìš©ìžë³„ ì¶”ì²œ ê²°ê³¼ë¥¼ ì €ìž¥í•  ë”•ì…”ë„ˆë¦¬ ì¶”ê°€ ðŸ’¥ðŸ’¥ðŸ’¥
case_study_results = {}

for user_idx in tqdm(test_users_indices, desc="Evaluating"):
    user_id_str = idx_to_user[user_idx]
    recs_indices, _ = model.recommend(
        userid=user_idx, user_items=train_matrix[user_idx],
        N=K_FOR_RANKING, filter_already_liked_items=False
    )
    already_liked_indices = set(train_matrix[user_idx].indices)
    filtered_recs_indices = [idx for idx in recs_indices if idx not in already_liked_indices]
    recommended_items = {idx_to_item[idx] for idx in filtered_recs_indices}
    
    # (Precision/Recall, Genre Similarity ê³„ì‚° ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼ - ìƒëžµ)
    ground_truth_items = true_relevants.get(user_id_str, set())
    if ground_truth_items:
        intersection = recommended_items.intersection(ground_truth_items)
        precisions.append(len(intersection) / K_FOR_RANKING)
        recalls.append(len(intersection) / len(ground_truth_items))
    user_train_data = train_df[train_df['user_id'] == user_id_str]
    if not user_train_data.empty:
        user_genre_data = user_train_data[existing_genre_cols]
        play_counts = user_train_data['play_count']
        user_profile_vector = (user_genre_data.mul(play_counts, axis=0).sum() / play_counts.sum()).values.reshape(1, -1)
        current_user_similarities = []
        for song_title in recommended_items:
            if song_title in song_features_matrix_map:
                song_vector = song_features_matrix_map[song_title].reshape(1, -1)
                similarity = cosine_similarity(user_profile_vector, song_vector)[0][0]
                current_user_similarities.append(similarity)
        if current_user_similarities:
            all_users_avg_similarities.append(np.mean(current_user_similarities))

    # ðŸ’¥ðŸ’¥ðŸ’¥ [ì‚¬ë¡€ ì—°êµ¬] í˜„ìž¬ ì‚¬ìš©ìžì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ìž¥ ðŸ’¥ðŸ’¥ðŸ’¥
    case_study_results[user_id_str] = {
        'profile_vector': user_profile_vector.flatten(),
        'recommendations': recommended_items
    }

avg_precision = np.mean(precisions) if precisions else 0
avg_recall = np.mean(recalls) if recalls else 0
f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) != 0 else 0
avg_genre_similarity = np.mean(all_users_avg_similarities) if all_users_avg_similarities else 0


# --- 6. ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
print("\n" + "="*60)
print(f"â–¶ ALS ëª¨ë¸ ì‹¬ì¸µ ì„±ëŠ¥ í‰ê°€ ìš”ì•½ (MSD, sklearn split)")
print("="*60)
print(f"\n[1. Top-{K_FOR_RANKING} ì¶”ì²œ ì„±ëŠ¥ ì§€í‘œ (ì •ë‹µë¥ )]\n")
print(f"Precision@{K_FOR_RANKING}: {avg_precision:.4f}")
print(f"Recall@{K_FOR_RANKING}   : {avg_recall:.4f}")
print(f"F1-Score@{K_FOR_RANKING}  : {f1_score:.4f}")
print("\n" + "-"*60)
print(f"\n[2. Top-{K_FOR_RANKING} ì½˜í…ì¸  ì •ë ¬ ì„±ëŠ¥ (ì·¨í–¥ ì¼ì¹˜ë„)]\n")
print(f"Average Genre Similarity: {avg_genre_similarity:.4f}")
print("="*60)


# --- 7. ðŸ’¥ðŸ’¥ðŸ’¥ ì‚¬ë¡€ ì—°êµ¬ (Case Study) ê²°ê³¼ ì¶œë ¥ ðŸ’¥ðŸ’¥ðŸ’¥ ---
print("\n" + "="*70)
print("â–¶ ì‚¬ë¡€ ì—°êµ¬: ëžœë¤ ì‚¬ìš©ìž 5ëª…ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„")
print("="*70)

# ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ìž ID ëª©ë¡ì—ì„œ 5ëª…ì„ ë¬´ìž‘ìœ„ë¡œ ì¶”ì¶œ
# ë§Œì•½ 5ëª…ë³´ë‹¤ ì ìœ¼ë©´, ê°€ëŠ¥í•œ ë§Œí¼ë§Œ ì¶”ì¶œ
num_samples = min(5, len(case_study_results))
random_users = random.sample(list(case_study_results.keys()), num_samples)

for i, user_id in enumerate(random_users):
    user_data = case_study_results[user_id]
    profile_vector = user_data['profile_vector']
    recommendations = user_data['recommendations']
    
    print(f"\n--- [Case {i+1}] User: {user_id} ---\n")
    
    # 1. ì‚¬ìš©ìžì˜ Top 5 ì„ í˜¸ ìž¥ë¥´ ì¶œë ¥
    # ì·¨í–¥ í”„ë¡œí•„ ë²¡í„°ë¥¼ (ìž¥ë¥´, ì ìˆ˜) ìŒìœ¼ë¡œ ë§Œë“  í›„, ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    user_top_genres = sorted(zip(existing_genre_cols, profile_vector), key=lambda x: x[1], reverse=True)
    
    print("  [ì‚¬ìš©ìž ì£¼ìš” ì·¨í–¥ (Top 5 Genres)]")
    for genre, score in user_top_genres[:5]:
        # ì ìˆ˜ê°€ 0.01ë³´ë‹¤ í° ê²½ìš°ì—ë§Œ ì˜ë¯¸ ìžˆëŠ” ì·¨í–¥ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ì¶œë ¥
        if score > 0.01:
            print(f"    - {genre:<25} ({score:.2%})") # í¼ì„¼íŠ¸ë¡œ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
            
    # 2. ì¶”ì²œëœ ë…¸ëž˜ ëª©ë¡ê³¼ ê° ë…¸ëž˜ì˜ Top 3 ìž¥ë¥´ ì¶œë ¥
    print("\n  [ALS ì¶”ì²œ ëª©ë¡ (Top K Songs & Genres)]")
    if not recommendations:
        print("    (ì¶”ì²œëœ ë…¸ëž˜ê°€ ì—†ìŠµë‹ˆë‹¤)")
    else:
        for song_title in recommendations:
            print(f"    - {song_title}")
            # ì¶”ì²œëœ ë…¸ëž˜ì˜ ìž¥ë¥´ ë²¡í„°ë¥¼ ê°€ì ¸ì™€ì„œ, ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
            if song_title in song_features_matrix_map:
                song_vector = song_features_matrix_map[song_title]
                song_top_genres = sorted(zip(existing_genre_cols, song_vector), key=lambda x: x[1], reverse=True)
                
                # í•´ë‹¹ ë…¸ëž˜ì˜ ì£¼ìš” ìž¥ë¥´(ì ìˆ˜ê°€ 0.01 ì´ìƒì¸)ë¥¼ ìµœëŒ€ 3ê°œê¹Œì§€ ì¶œë ¥
                genre_str = ", ".join([f"{g}" for g, s in song_top_genres[:5] if s > 0.01])
                print(f"      â””â”€ Genres: {genre_str if genre_str else 'N/A'}")

print("\n" + "="*70)